{
    "docs": [
        {
            "location": "/", 
            "text": "The ReSpeaker Project\n\n\n\n\nNote\n\n\nThe website is still under construction\n\n\n\n\nThe ReSpeaker project provides hardware components and software libraries to build voice enabled device.\n\n\n\n\nHardware\n\n\nThe hardware components include I2S microphone array for Raspberry Pi, USB microphone array for Linux/Windows/macOS, standalone ReSpeaker Core v1.0 \n v2.0.\n\n\nMicrophone Array\n\n\n\n\n\n\n\n\n\n\nUSB 4 Mic Array\n\n\n2 Mic Array for Pi\n\n\n4 Mic Array for Pi\n\n\n4 Linear Mic Array for Pi\n\n\n6 Mic Array for Pi\n\n\n\n\n\n\n\n\n\n\nMicrophones\n\n\n4\n\n\n2\n\n\n4\n\n\n4\n\n\n6\n\n\n\n\n\n\nShape\n\n\ncircular\n\n\nlinear\n\n\nsquare\n\n\nlinear\n\n\nhexagon\n\n\n\n\n\n\nInterface\n\n\nUSB\n\n\nI2S\n\n\nI2S\n\n\nI2S\n\n\nI2S\n\n\n\n\n\n\nRGB LEDs\n\n\n12\n\n\n3\n\n\n12\n\n\nNA\n\n\n12\n\n\n\n\n\n\nAudio Output\n\n\nMono\n\n\nStereo\n\n\nNA\n\n\nStereo\n\n\nStereo\n\n\n\n\n\n\nNote\n\n\nbuilt-in algorithms\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you are looking for a custom shape mic array, you may want to try \nSeeed's Fusion service\n to design a new one based on our design. It should be easy.\n\n\nStandalone ReSpeaker Core\n\n\n\n\n\n\n\n\n\n\nReSpeaker Core v1 (MT7688)\n\n\nReSpeaker Core v2 (RK3229)\n\n\n\n\n\n\n\n\n\n\nCPU\n\n\nMT7688 (MIPS24KEc, 580 MHz)\n\n\nRK3229 (4 ARM Cortex A7 cores, 1.5GHz)\n\n\n\n\n\n\nRAM\n\n\n256 MB\n\n\n1 GB\n\n\n\n\n\n\nMicrophones\n\n\n1\n\n\n6\n\n\n\n\n\n\nShape\n\n\ncircular\n\n\nhexagon\n\n\n\n\n\n\nInterfaces\n\n\nWiFi, USB device\n\n\nWiFi, Bluetooth, Ethernet, HDMI, USB otg/host\n\n\n\n\n\n\nloopback\n\n\nNA\n\n\n2 channels\n\n\n\n\n\n\n\n\nSoftware\n\n\nAudio processing algorithms includes VAD, DOA, Beamforming, NS, AEC and KWS.", 
            "title": "Overview"
        }, 
        {
            "location": "/#the-respeaker-project", 
            "text": "Note  The website is still under construction   The ReSpeaker project provides hardware components and software libraries to build voice enabled device.", 
            "title": "The ReSpeaker Project"
        }, 
        {
            "location": "/#hardware", 
            "text": "The hardware components include I2S microphone array for Raspberry Pi, USB microphone array for Linux/Windows/macOS, standalone ReSpeaker Core v1.0   v2.0.", 
            "title": "Hardware"
        }, 
        {
            "location": "/#microphone-array", 
            "text": "USB 4 Mic Array  2 Mic Array for Pi  4 Mic Array for Pi  4 Linear Mic Array for Pi  6 Mic Array for Pi      Microphones  4  2  4  4  6    Shape  circular  linear  square  linear  hexagon    Interface  USB  I2S  I2S  I2S  I2S    RGB LEDs  12  3  12  NA  12    Audio Output  Mono  Stereo  NA  Stereo  Stereo    Note  built-in algorithms         If you are looking for a custom shape mic array, you may want to try  Seeed's Fusion service  to design a new one based on our design. It should be easy.", 
            "title": "Microphone Array"
        }, 
        {
            "location": "/#standalone-respeaker-core", 
            "text": "ReSpeaker Core v1 (MT7688)  ReSpeaker Core v2 (RK3229)      CPU  MT7688 (MIPS24KEc, 580 MHz)  RK3229 (4 ARM Cortex A7 cores, 1.5GHz)    RAM  256 MB  1 GB    Microphones  1  6    Shape  circular  hexagon    Interfaces  WiFi, USB device  WiFi, Bluetooth, Ethernet, HDMI, USB otg/host    loopback  NA  2 channels", 
            "title": "Standalone ReSpeaker Core"
        }, 
        {
            "location": "/#software", 
            "text": "Audio processing algorithms includes VAD, DOA, Beamforming, NS, AEC and KWS.", 
            "title": "Software"
        }, 
        {
            "location": "/2_mic_array/", 
            "text": "ReSpeaker 2 Mic Array for Raspberry Pi\n\n\n\n\nThe ReSpeaker 2 Mic Array (ReSpeaker 2-Mics Pi HAT) is a 2 microphone array Pi Hat for Raspberry Pi designed for AI and voice applications. This means that you can build a more powerful and flexible voice product that integrates Amazon Alexa Voice Service, Google Assistant, and so on.\n\n\nThe board is based on WM8960, a low power stereo codec. There are 2 microphones on both sides of the board for collecting sounds and it also provides 3 APA102 RGB LEDs, 1 User Button and 2 on-board Grove interfaces for expanding your applications. What is more, 3.5mm Audio Jack or JST 2.0 Speaker Out are both available for audio output.\n\n\nResources\n\n\n\n\nLinux driver for Raspberry Pi\n\n\nGoogle Assistant Demo \n Alexa Demo\n\n\nVoice Engine project, provides building blocks to create voice enabled objects\n\n\nAcoustic Echo Cancellation (AEC) project\n\n\n\n\nWiki\n\n\nhttp://wiki.seeedstudio.com/ReSpeaker_2_Mics_Pi_HAT/", 
            "title": "2 Mic Array for Pi"
        }, 
        {
            "location": "/2_mic_array/#respeaker-2-mic-array-for-raspberry-pi", 
            "text": "The ReSpeaker 2 Mic Array (ReSpeaker 2-Mics Pi HAT) is a 2 microphone array Pi Hat for Raspberry Pi designed for AI and voice applications. This means that you can build a more powerful and flexible voice product that integrates Amazon Alexa Voice Service, Google Assistant, and so on.  The board is based on WM8960, a low power stereo codec. There are 2 microphones on both sides of the board for collecting sounds and it also provides 3 APA102 RGB LEDs, 1 User Button and 2 on-board Grove interfaces for expanding your applications. What is more, 3.5mm Audio Jack or JST 2.0 Speaker Out are both available for audio output.", 
            "title": "ReSpeaker 2 Mic Array for Raspberry Pi"
        }, 
        {
            "location": "/2_mic_array/#resources", 
            "text": "Linux driver for Raspberry Pi  Google Assistant Demo   Alexa Demo  Voice Engine project, provides building blocks to create voice enabled objects  Acoustic Echo Cancellation (AEC) project", 
            "title": "Resources"
        }, 
        {
            "location": "/2_mic_array/#wiki", 
            "text": "http://wiki.seeedstudio.com/ReSpeaker_2_Mics_Pi_HAT/", 
            "title": "Wiki"
        }, 
        {
            "location": "/4_mic_array/", 
            "text": "ReSpeaker 4 Mic Array for Raspberry Pi\n\n\n\n\n\n\nThe ReSpeaker 4 Mic Array for Raspberry Pi is a Pi hat with a 12 RGB LEDs ring.\nIt is designed to build voice enabled applications such as Google Assistant and Alexa.\n\n\nThere are several algorithms such as DOA, VAD, NS and KWS we can use with the 4 mic array.\n\n\nIf you need other shape of mic array or need audio output, you may take a look of \nthe Hexagon 6 Mic Array for Pi\n, \nthe Linear 4 Mic Array\n and \n2 mic hat for pi\n. If you want a custom shape mic array, you may try \nSeeed's Fusion service\n to design a new one. It should be easy.\n\n\nSound Source Localization \n Tracking\n\n\nODAS\n is a very cool project to perform sound source localization, tracking, separation and post-filtering. Let's have a try!\n\n\n\n\n\n\n\n\nget ODAS and build it\n\n\nsudo apt-get install libfftw3-dev libconfig-dev libasound2-dev\ngit clone https://github.com/introlab/odas.git\nmkdir odas/build\ncd odas/build\ncmake ..\nmake\n\n\n\n\n\n\n\nget ODAS Studio from https://github.com/introlab/odas_web/releases and open it. You can run ODAS Studio on a computer or the Raspberry Pi.\n\n\nThe \nodascore\n will be at \nodas/bin/odascore\n, the config file is at \nodas/config/respeaker_4_mic_array.cfg\n. Change \nodas.cfg\n based on your sound card number.\n\n\ninterface: {\n    type = \"soundcard\";\n    card = 1;\n    device = 0;\n}\n\n\n\nIf you run the ODAS Studio on a computer, you should also need to change IP address from \n127.0.0.1\n to the IP of the computer.\n\n\n\n\n\n\nResources\n\n\n\n\nLinux driver for Raspberry Pi\n\n\nAlgorithms includes DOA, VAD, NS\n\n\nVoice Engine project, provides building blocks to create voice enabled objects\n\n\nAcoustic Echo Cancellation (AEC) project\n\n\n\n\nWiki\n\n\nhttp://wiki.seeedstudio.com/ReSpeaker_4_Mic_Array_for_Raspberry_Pi", 
            "title": "4 Mic Array for Pi"
        }, 
        {
            "location": "/4_mic_array/#respeaker-4-mic-array-for-raspberry-pi", 
            "text": "The ReSpeaker 4 Mic Array for Raspberry Pi is a Pi hat with a 12 RGB LEDs ring.\nIt is designed to build voice enabled applications such as Google Assistant and Alexa.  There are several algorithms such as DOA, VAD, NS and KWS we can use with the 4 mic array.  If you need other shape of mic array or need audio output, you may take a look of  the Hexagon 6 Mic Array for Pi ,  the Linear 4 Mic Array  and  2 mic hat for pi . If you want a custom shape mic array, you may try  Seeed's Fusion service  to design a new one. It should be easy.", 
            "title": "ReSpeaker 4 Mic Array for Raspberry Pi"
        }, 
        {
            "location": "/4_mic_array/#sound-source-localization-tracking", 
            "text": "ODAS  is a very cool project to perform sound source localization, tracking, separation and post-filtering. Let's have a try!     get ODAS and build it  sudo apt-get install libfftw3-dev libconfig-dev libasound2-dev\ngit clone https://github.com/introlab/odas.git\nmkdir odas/build\ncd odas/build\ncmake ..\nmake    get ODAS Studio from https://github.com/introlab/odas_web/releases and open it. You can run ODAS Studio on a computer or the Raspberry Pi.  The  odascore  will be at  odas/bin/odascore , the config file is at  odas/config/respeaker_4_mic_array.cfg . Change  odas.cfg  based on your sound card number.  interface: {\n    type = \"soundcard\";\n    card = 1;\n    device = 0;\n}  If you run the ODAS Studio on a computer, you should also need to change IP address from  127.0.0.1  to the IP of the computer.", 
            "title": "Sound Source Localization &amp; Tracking"
        }, 
        {
            "location": "/4_mic_array/#resources", 
            "text": "Linux driver for Raspberry Pi  Algorithms includes DOA, VAD, NS  Voice Engine project, provides building blocks to create voice enabled objects  Acoustic Echo Cancellation (AEC) project", 
            "title": "Resources"
        }, 
        {
            "location": "/4_mic_array/#wiki", 
            "text": "http://wiki.seeedstudio.com/ReSpeaker_4_Mic_Array_for_Raspberry_Pi", 
            "title": "Wiki"
        }, 
        {
            "location": "/linear_4_mic_array/", 
            "text": "ReSpeaker Linear 4 Mic Array for Raspberry Pi\n\n\n\n\n\n\nThe ReSpeaker Linear 4 Mic Array for Raspberry Pi is a Pi hat with 4 microphones, 2 audio output channels and 2 loopback channels.\nThe 2 loopback channels can be used for Acoustic Echo Cancellation (AEC). It has two parts, the main part and the linear mic array part.\n\n\nIf you are looking for other shape of mic array, you may take a look of \nthe Hexagon 6 Mic Array for Pi\n, \nthe Square 4 Mic Array\n and \n2 mic hat for pi\n. Or if you want a custom shape mic array, you may try \nSeeed's Fusion service\n to design a new one. It should be easy.\n\n\nResources\n\n\n\n\nLinux driver for Raspberry Pi\n\n\nAlgorithms includes DOA, VAD, NS\n\n\nVoice Engine project, provides building blocks to create voice enabled objects\n\n\nAcoustic Echo Cancellation (AEC) project\n\n\n\n\nWiki\n\n\nhttp://wiki.seeedstudio.com/ReSpeaker_4-Mic_Linear_Array_Kit_for_Raspberry_Pi/", 
            "title": "Linear 4 Mic Array for Pi"
        }, 
        {
            "location": "/linear_4_mic_array/#respeaker-linear-4-mic-array-for-raspberry-pi", 
            "text": "The ReSpeaker Linear 4 Mic Array for Raspberry Pi is a Pi hat with 4 microphones, 2 audio output channels and 2 loopback channels.\nThe 2 loopback channels can be used for Acoustic Echo Cancellation (AEC). It has two parts, the main part and the linear mic array part.  If you are looking for other shape of mic array, you may take a look of  the Hexagon 6 Mic Array for Pi ,  the Square 4 Mic Array  and  2 mic hat for pi . Or if you want a custom shape mic array, you may try  Seeed's Fusion service  to design a new one. It should be easy.", 
            "title": "ReSpeaker Linear 4 Mic Array for Raspberry Pi"
        }, 
        {
            "location": "/linear_4_mic_array/#resources", 
            "text": "Linux driver for Raspberry Pi  Algorithms includes DOA, VAD, NS  Voice Engine project, provides building blocks to create voice enabled objects  Acoustic Echo Cancellation (AEC) project", 
            "title": "Resources"
        }, 
        {
            "location": "/linear_4_mic_array/#wiki", 
            "text": "http://wiki.seeedstudio.com/ReSpeaker_4-Mic_Linear_Array_Kit_for_Raspberry_Pi/", 
            "title": "Wiki"
        }, 
        {
            "location": "/6_mic_array/", 
            "text": "ReSpeaker 6 Mic Array for Raspberry Pi\n\n\n\n\n\n\nThe ReSpeaker 6 Mic Array for Raspberry Pi is a Pi hat with 6 microphones, 2 audio output channels and 2 loopback channels.\nThe 2 loopback channels can be used for Acoustic Echo Cancellation (AEC). It has two parts, the main part and the mic array part.\n\n\nThere are several algorithms such as DOA, VAD, NS and KWS we can use with the 6 mic array.\n\n\nIf you are looking for a custom shape mic array, you may try \nSeeed's Fusion service\n to design a new one. It should be easy.\n\n\nSound Source Localization \n Tracking\n\n\nODAS\n is a very cool project to perform sound source localization, tracking, separation and post-filtering. Let's have a try!\n\n\n\n\n\n\n\n\nget ODAS and build it\n\n\nsudo apt-get install libfftw3-dev libconfig-dev libasound2-dev\ngit clone https://github.com/introlab/odas.git\nmkdir odas/build\ncd odas/build\ncmake ..\nmake\n\n\n\n\n\n\n\nget ODAS Studio from https://github.com/introlab/odas_web/releases and open it. You can run ODAS Studio on a computer or the Raspberry Pi.\n\n\nThe \nodaslive\n will be at \nodas/bin/odaslive\n, the config file is \nrespeaker_6_mic_array.cfg\n. Change \ncard = 1\n based on your sound card number.\n\n\ninterface: {\n    type = \"soundcard\";\n    card = 1;\n    device = 0;\n}\n\n\n\nIf you run the ODAS Studio on a computer, you should also need to change IP address from \n127.0.0.1\n to the IP of the computer.\n\n\n\n\n\n\nResources\n\n\n\n\nLinux driver for Raspberry Pi\n\n\nAlgorithms includes DOA, VAD, NS\n\n\nVoice Engine project, provides building blocks to create voice enabled objects\n\n\n\n\nWiki\n\n\nhttp://wiki.seeedstudio.com/ReSpeaker_6-Mic_Circular_Array_kit_for_Raspberry_Pi/", 
            "title": "6 Mic Array for Pi"
        }, 
        {
            "location": "/6_mic_array/#respeaker-6-mic-array-for-raspberry-pi", 
            "text": "The ReSpeaker 6 Mic Array for Raspberry Pi is a Pi hat with 6 microphones, 2 audio output channels and 2 loopback channels.\nThe 2 loopback channels can be used for Acoustic Echo Cancellation (AEC). It has two parts, the main part and the mic array part.  There are several algorithms such as DOA, VAD, NS and KWS we can use with the 6 mic array.  If you are looking for a custom shape mic array, you may try  Seeed's Fusion service  to design a new one. It should be easy.", 
            "title": "ReSpeaker 6 Mic Array for Raspberry Pi"
        }, 
        {
            "location": "/6_mic_array/#sound-source-localization-tracking", 
            "text": "ODAS  is a very cool project to perform sound source localization, tracking, separation and post-filtering. Let's have a try!     get ODAS and build it  sudo apt-get install libfftw3-dev libconfig-dev libasound2-dev\ngit clone https://github.com/introlab/odas.git\nmkdir odas/build\ncd odas/build\ncmake ..\nmake    get ODAS Studio from https://github.com/introlab/odas_web/releases and open it. You can run ODAS Studio on a computer or the Raspberry Pi.  The  odaslive  will be at  odas/bin/odaslive , the config file is  respeaker_6_mic_array.cfg . Change  card = 1  based on your sound card number.  interface: {\n    type = \"soundcard\";\n    card = 1;\n    device = 0;\n}  If you run the ODAS Studio on a computer, you should also need to change IP address from  127.0.0.1  to the IP of the computer.", 
            "title": "Sound Source Localization &amp; Tracking"
        }, 
        {
            "location": "/6_mic_array/#resources", 
            "text": "Linux driver for Raspberry Pi  Algorithms includes DOA, VAD, NS  Voice Engine project, provides building blocks to create voice enabled objects", 
            "title": "Resources"
        }, 
        {
            "location": "/6_mic_array/#wiki", 
            "text": "http://wiki.seeedstudio.com/ReSpeaker_6-Mic_Circular_Array_kit_for_Raspberry_Pi/", 
            "title": "Wiki"
        }, 
        {
            "location": "/usb_4_mic_array/", 
            "text": "The ReSpeaker USB 4 Mic Array is the successor of the ReSpeaker USB 6+1 Mic Array. It has better built-in audio processing algorithms than the 6+1 Mic Array, so it has better audio recording quality, although it only has 4 microphones.\n\n\n\n\nFeatures\n\n\n\n\n4 microphones\n\n\n12 RGB LEDs\n\n\nUSB\n\n\nbuilt-in AEC, VAD, DOA, Beamforming and NS\n\n\n16000 sample rate\n\n\n\n\nUsage\n\n\nAudacity\n is recommended.\n\n\nLED control driver for Windows\n\n\nOn Linux and macOS, the USB 4 Mic Array will just work. On Windows, audio recording and playback will also work without installing a driver. But in order to control LEDs and to tune DSP parameters on Windows, the libusb-win32 driver is required. We use \na handy tool - Zadig\n to install the libusb-win32 driver for both \nSEEED DFU\n and \nSEEED Control\n (the USB 4 Mic Array has 4 devices on Windows Device Manager).\n\n\n\n\n\n\nNote\n\n\nMake sure that libusb-win32 is selected, not WinUSB or libusbK\n\n\n\n\nDevice Firmware Update on Linux\n\n\nThe Microphone Array supports USB DFU. We have \na python script dfu.py\n to do that.\n\n\nwget https://github.com/respeaker/mic_array_dfu/raw/master/dfu.py\npip install pyusb\npython dfu.py --download new_firmware.bin\n\n\n\n\n\n\nNote\n\n\nThe USB DFU on Windows is buggy, some Windows work (tested on Surface Book), but some Windows don't. Using Linux to change its firmware is recommended.\n\n\n\n\nHow to control the RGB LED ring\n\n\nThe USB 4 Mic Array has on-board 12 RGB LEDs and has a variety of light effects. Go to the \nrespeaker/pixel_ring\n to learn how to use it. The LED control protocol is at \nrespeaker/pixel_ring wiki\n.\n\n\nTuning\n\n\nThere are some parameters of built-in algorithms to configure. For example, we can turn off Automatic Gain Control (AGC):\n\n\npython tuning.py AGCONOFF 0\n\n\n\n\nTo get the full list parameters, run:\n\n\npython tuning.py -p\n\n\n\n\nRealtime sound source localization and tracking\n\n\nODAS\n is a very cool project to perform sound source localization, tracking, separation and post-filtering. Let's have a try!\n\n\n\n\nget ODAS and build it\n\n\n\n\nsudo apt-get install libfftw3-dev libconfig-dev libasound2-dev\ngit clone https://github.com/introlab/odas.git --branch=dev\nmkdir odas/build\ncd odas/build\ncmake ..\nmake\n\n\n\n\n\n\nget ODAS Studio from https://github.com/introlab/odas_web/releases and open it.\n\n\n\n\nThe \nodascore\n will be at \nodas/bin/odascore\n, the config file is at \nodas.cfg\n. Change \nodas.cfg\n based on your sound card number.\n\n\n    interface: {\n        type = \nsoundcard\n;\n        card = 1;\n        device = 0;\n    }\n\n\n\n\n\n\nupgrade your usb 4 mic array with \ni6_firmware.bin\n which provides 4 channels raw audio data.", 
            "title": "USB 4 Mic Array"
        }, 
        {
            "location": "/usb_4_mic_array/#features", 
            "text": "4 microphones  12 RGB LEDs  USB  built-in AEC, VAD, DOA, Beamforming and NS  16000 sample rate", 
            "title": "Features"
        }, 
        {
            "location": "/usb_4_mic_array/#usage", 
            "text": "Audacity  is recommended.", 
            "title": "Usage"
        }, 
        {
            "location": "/usb_4_mic_array/#led-control-driver-for-windows", 
            "text": "On Linux and macOS, the USB 4 Mic Array will just work. On Windows, audio recording and playback will also work without installing a driver. But in order to control LEDs and to tune DSP parameters on Windows, the libusb-win32 driver is required. We use  a handy tool - Zadig  to install the libusb-win32 driver for both  SEEED DFU  and  SEEED Control  (the USB 4 Mic Array has 4 devices on Windows Device Manager).    Note  Make sure that libusb-win32 is selected, not WinUSB or libusbK", 
            "title": "LED control driver for Windows"
        }, 
        {
            "location": "/usb_4_mic_array/#device-firmware-update-on-linux", 
            "text": "The Microphone Array supports USB DFU. We have  a python script dfu.py  to do that.  wget https://github.com/respeaker/mic_array_dfu/raw/master/dfu.py\npip install pyusb\npython dfu.py --download new_firmware.bin   Note  The USB DFU on Windows is buggy, some Windows work (tested on Surface Book), but some Windows don't. Using Linux to change its firmware is recommended.", 
            "title": "Device Firmware Update on Linux"
        }, 
        {
            "location": "/usb_4_mic_array/#how-to-control-the-rgb-led-ring", 
            "text": "The USB 4 Mic Array has on-board 12 RGB LEDs and has a variety of light effects. Go to the  respeaker/pixel_ring  to learn how to use it. The LED control protocol is at  respeaker/pixel_ring wiki .", 
            "title": "How to control the RGB LED ring"
        }, 
        {
            "location": "/usb_4_mic_array/#tuning", 
            "text": "There are some parameters of built-in algorithms to configure. For example, we can turn off Automatic Gain Control (AGC):  python tuning.py AGCONOFF 0  To get the full list parameters, run:  python tuning.py -p", 
            "title": "Tuning"
        }, 
        {
            "location": "/usb_4_mic_array/#realtime-sound-source-localization-and-tracking", 
            "text": "ODAS  is a very cool project to perform sound source localization, tracking, separation and post-filtering. Let's have a try!   get ODAS and build it   sudo apt-get install libfftw3-dev libconfig-dev libasound2-dev\ngit clone https://github.com/introlab/odas.git --branch=dev\nmkdir odas/build\ncd odas/build\ncmake ..\nmake   get ODAS Studio from https://github.com/introlab/odas_web/releases and open it.   The  odascore  will be at  odas/bin/odascore , the config file is at  odas.cfg . Change  odas.cfg  based on your sound card number.      interface: {\n        type =  soundcard ;\n        card = 1;\n        device = 0;\n    }   upgrade your usb 4 mic array with  i6_firmware.bin  which provides 4 channels raw audio data.", 
            "title": "Realtime sound source localization and tracking"
        }, 
        {
            "location": "/usb_6+1_mic_array/", 
            "text": "USB 6+1 Mic Array\n\n\n\n\nNote\n\n\nThe USB 6+1 Mic Array is discontinued as its main IC is discontinued by the IC vendor.\n\nIts successor USB 4 Mic Array\n will come soon. The USB 4 Mic Array has better built-in audio processing algorithms.\n\n\n\n\n\n\nThe USB 6+1 Mic Array is a circular microphone array with a 12 RGB LEDs ring. It has builtin VAD, DOA, NS and Beamforming algorithms.\n\n\nThe 12 RGB LEDs are programmable and can be controled through USB HID interface. The Mic Array also supports USB DFU to change its firmware. There is a firmware providing 8 channels audio data (7 channels raw data, 1 combined channel).\n\n\nResources\n\n\n\n\nrespeaker python library\n for audio recording and LED control\n\n\nAlgorithms for raw data mic array", 
            "title": "USB 6+1 Mic Array"
        }, 
        {
            "location": "/usb_6+1_mic_array/#usb-61-mic-array", 
            "text": "Note  The USB 6+1 Mic Array is discontinued as its main IC is discontinued by the IC vendor. Its successor USB 4 Mic Array  will come soon. The USB 4 Mic Array has better built-in audio processing algorithms.    The USB 6+1 Mic Array is a circular microphone array with a 12 RGB LEDs ring. It has builtin VAD, DOA, NS and Beamforming algorithms.  The 12 RGB LEDs are programmable and can be controled through USB HID interface. The Mic Array also supports USB DFU to change its firmware. There is a firmware providing 8 channels audio data (7 channels raw data, 1 combined channel).", 
            "title": "USB 6+1 Mic Array"
        }, 
        {
            "location": "/usb_6+1_mic_array/#resources", 
            "text": "respeaker python library  for audio recording and LED control  Algorithms for raw data mic array", 
            "title": "Resources"
        }, 
        {
            "location": "/mt7688_core/", 
            "text": "ReSpeaker Core 7688\n\n\n\n\nThe ReSpeaker Core 7688 has 1 microphones, stereo audio output, on-board class-d audio amplifier, on-board ATmega32U4, 12 RGB LEDs and 8 touch sensors.\n\n\nResources\n\n\n\n\nrespeaker python library\n for audio recording and LED control\n\n\nrespeaker arduino library", 
            "title": "ReSpeaker Core v1.0 (MT7688)"
        }, 
        {
            "location": "/mt7688_core/#respeaker-core-7688", 
            "text": "The ReSpeaker Core 7688 has 1 microphones, stereo audio output, on-board class-d audio amplifier, on-board ATmega32U4, 12 RGB LEDs and 8 touch sensors.", 
            "title": "ReSpeaker Core 7688"
        }, 
        {
            "location": "/mt7688_core/#resources", 
            "text": "respeaker python library  for audio recording and LED control  respeaker arduino library", 
            "title": "Resources"
        }, 
        {
            "location": "/rk3229_core/", 
            "text": "ReSpeaker Core v2.0 (RK3229)\n\n\n\n\nSeeed\u2019s ReSpeaker Core v2.0 is designed for voice interface applications. It is based on the Rockchip RK3229, a quad-core ARM Cortex A7, running up to 1.5GHz, with 1GB RAM. The board features a six microphone array with speech algorithms including DoA (Direction of Arrival), BF (Beamforming), AEC (Acoustic Echo Cancellation), etc.\n\n\nReSpeaker Core v2.0 runs a GNU/Linux operating system (Debian). It benefits from a powerful and active community allowing for the use of existing software and tools for development, testing, and deployment, enabling rapid product development.\n\n\nReSpeaker Core v2.0 is designed as a feature rich development board for businesses to evaluate. To this end the board consists of two main sections, the first being the center core module containing the CPU, Memory (RAM), and PMU. The second section is the outer carrier board which contains the peripherals such as the eMMC, connectors, and wireless connectivity components. Either section or both can be customized through Seeed\u2019s customization services.\n\n\nFeatures\n\n\n\n\nDebian-Based Linux System\n\n\nSDK for Speech Algorithms with Full Documents\n\n\nC++ SDK and Python Wrapper\n\n\n\n\nSpeech Algorithms and Features\n\n\n\n\n\n\nKeyword Spotting (Wake-Up)\n\n\n\n\nBF (Beamforming)\n\n\nDoA (Direction of Arrival)\n\n\nNS (Noise Suppression)\n\n\n\n\nAEC (Acoustic Echo Cancellation) and AGC (Automatic Gain Control)\n\n\n\n\n\n\nAll-in-One Solution with High Performance SoC\n\n\n\n\n8 Channel ADC for 6 Microphone Array and 2 Loopbacks (Hardware Loopback)\n\n\n\n\nResources\n\n\n\n\nAudio front-end processing algorithms including AEC, Beamforming, NS and KWS\n\n\nGoogle Assistant Demo\n\n\nAlexa Voice Service C++ SDK for ReSpeaker Core v2.0\n\n\nAlexa Voice Service \n DuerOS Python SDK\n\n\nRGB LEDs library\n\n\nMicrosoft Speech Translation Demo\n\n\n\n\nWiki\n\n\nhttp://wiki.seeedstudio.com/ReSpeaker_Core_v2.0/", 
            "title": "ReSpeaker Core v2.0 (RK3229)"
        }, 
        {
            "location": "/rk3229_core/#respeaker-core-v20-rk3229", 
            "text": "Seeed\u2019s ReSpeaker Core v2.0 is designed for voice interface applications. It is based on the Rockchip RK3229, a quad-core ARM Cortex A7, running up to 1.5GHz, with 1GB RAM. The board features a six microphone array with speech algorithms including DoA (Direction of Arrival), BF (Beamforming), AEC (Acoustic Echo Cancellation), etc.  ReSpeaker Core v2.0 runs a GNU/Linux operating system (Debian). It benefits from a powerful and active community allowing for the use of existing software and tools for development, testing, and deployment, enabling rapid product development.  ReSpeaker Core v2.0 is designed as a feature rich development board for businesses to evaluate. To this end the board consists of two main sections, the first being the center core module containing the CPU, Memory (RAM), and PMU. The second section is the outer carrier board which contains the peripherals such as the eMMC, connectors, and wireless connectivity components. Either section or both can be customized through Seeed\u2019s customization services.", 
            "title": "ReSpeaker Core v2.0 (RK3229)"
        }, 
        {
            "location": "/rk3229_core/#features", 
            "text": "Debian-Based Linux System  SDK for Speech Algorithms with Full Documents  C++ SDK and Python Wrapper   Speech Algorithms and Features    Keyword Spotting (Wake-Up)   BF (Beamforming)  DoA (Direction of Arrival)  NS (Noise Suppression)   AEC (Acoustic Echo Cancellation) and AGC (Automatic Gain Control)    All-in-One Solution with High Performance SoC   8 Channel ADC for 6 Microphone Array and 2 Loopbacks (Hardware Loopback)", 
            "title": "Features"
        }, 
        {
            "location": "/rk3229_core/#resources", 
            "text": "Audio front-end processing algorithms including AEC, Beamforming, NS and KWS  Google Assistant Demo  Alexa Voice Service C++ SDK for ReSpeaker Core v2.0  Alexa Voice Service   DuerOS Python SDK  RGB LEDs library  Microsoft Speech Translation Demo", 
            "title": "Resources"
        }, 
        {
            "location": "/rk3229_core/#wiki", 
            "text": "http://wiki.seeedstudio.com/ReSpeaker_Core_v2.0/", 
            "title": "Wiki"
        }, 
        {
            "location": "/make_a_smart_speaker/", 
            "text": "To make a smart speaker\n\n\n\n\n Github\n\n\n\n\nHere is a collection of resources to make a smart speaker. Hope one day we can make an open source one for daily use.\n\n\nThe simplified flowchart of a smart speaker is like:\n\n\n+---+   +----------------+   +---+   +---+   +---+\n|Mic|--\n|Audio Processing|--\n|KWS|--\n|STT|--\n|NLU|\n+---+   +----------------+   +---+   +---+   +-+-+\n                                               |\n                                               |\n+-------+   +---+   +----------------------+   |\n|Speaker|\n--|TTS|\n--|Knowledge/Skill/Action|\n--+\n+-------+   +---+   +----------------------+\n\n\n\n\n\n\nAudio Processing includes Acoustic Echo Cancellation (AEC), Beamforming, Noise Suppression (NS), etc.\n\n\nKeyword Spotting (KWS) detects a keyword (such as OK Google, Hey Siri) to start a conversation.\n\n\nSpeech To Text (STT)\n\n\nNatural Language Understanding (NLU) converts raw text into structured data.\n\n\nKnowledge/Skill/Action - Knowledge base and plugins (Alexa Skill, Google Action) to provide an answer.\n\n\nText To Speech\n\n\n\n\n\n\nKWS + STT + NLU + Skill + TTS\n\n\nActive open source projects\n\n\n\n\nMycroft\n -  a hackable open source voice assistant\n\n\ndingdang robot\n - a Chinese voice interaction robot based on \nJasper\n and built with raspberry pi\n\n\n\n\nSDK\n\n\n\n\n\n\nAmazon Alexa Voice Service - is the most widely used voice assistant\n\n\n\n\n\n\nC++ SDK\n\n\n\n\nJava Client\n\n\n\n\nPython Client\n\n\n\n\n\n\nGoogle Assistant SDK\n\n\n\n\n\n\nIt has the smartest brain, its extension called Google Action can be created on a few steps with digitalflow.ai and its Device Action is very suit for home smart devices.\n\n\n\n\nBaidu DuerOS\n\n\n\n\nKWS\n\n\n\n\nMycroft Precise\n - A lightweight, simple-to-use, RNN wake word listener\n\n\nSnowboy\n - DNN based hotword and wake word detection toolkit\n\n\nHonk\n - PyTorch reimplementation of Google's TensorFlow CNNs for keyword spotting\n\n\nML-KWS-For-MCU\n - Maybe the most promise for resource constrained devices such as ARM Cortex M7 microcontroller\n\n\n\n\nSTT\n\n\n\n\nMozilla DeepSpeech\n - A TensorFlow implementation of Baidu's DeepSpeech architecture\n\n\nKaldi\n\n\nPocketSphinx\n - a lightweight speech recognition engine using HMM + GMM\n\n\n\n\nNLU\n\n\n\n\n\n\nRasa NLU\n\n\n\n\n\n\nRasa NLU for Chinese\n\n\n\n\n\n\nSnips NLU\n - a Python library that allows to parse sentences written in natural language and extracts structured information.\n\n\n\n\n\n\nTTS\n\n\n\n\nMimic\n - Mycroft's TTS engine, based on CMU's Flite (Festival Lite)\n\n\nmanytts\n - an open-source, multilingual text-to-speech synthesis system written in pure java\n\n\nespeak-ng\n - an open source speech synthesizer that supports 99 languages and accents.\n\n\nekho\n - Chinese text-to-speech engine\n\n\nWaveNet, Tacotron 2\n\n\n\n\nAudio Processing\n\n\n\n\n\n\nAcoustic Echo Cancellation\n\n\n\n\n\n\nSpeexDSP\n, its python binding \nspeexdsp-python\n\n\n\n\n\n\nEC\n - Echo Cancelation Daemon based on SpeexDSP AEC for Raspberry Pi or other devices running Linux.\n\n\n\n\n\n\nDirection Of Arrival (DOA) - Most used DOA algorithms is GCC-PHAT\n\n\n\n\n\n\ntdoa\n\n\n\n\n\n\nodas\n - ODAS stands for Open embeddeD Audition System. This is a library dedicated to perform sound source localization, tracking, separation and post-filtering. ODAS is coded entirely in C, for more portability, and is optimized to run easily on low-cost embedded hardware. ODAS is free and open source.\n\n\n\n\n\n\nBeamforming\n\n\n\n\n\n\nBeamformIt\n - filter\nsum beamforming\n\n\n\n\nCGMM Beamforming - \na reference implementation\n\n\nMVDR Beamforming\n\n\n\n\nGSC Beamforming\n\n\n\n\n\n\nVoice Activity Detection\n\n\n\n\n\n\nWebRTC VAD, \npy-webrtcvad\n\n\n\n\n\n\nDNN VAD\n\n\n\n\n\n\nNoise Suppresion\n\n\n\n\n\n\nNS of WebRTC audio processing, \npython-webrtc-audio-processing\n\n\n\n\n\n\nAudio I/O\n\n\n\n\nPortAudio, pyaudio\n\n\nlibsoundio\n\n\nALSA\n\n\nPulseAudio\n\n\nPipewire", 
            "title": "Make a smart speaker"
        }, 
        {
            "location": "/make_a_smart_speaker/#to-make-a-smart-speaker", 
            "text": "Github   Here is a collection of resources to make a smart speaker. Hope one day we can make an open source one for daily use.  The simplified flowchart of a smart speaker is like:  +---+   +----------------+   +---+   +---+   +---+\n|Mic|-- |Audio Processing|-- |KWS|-- |STT|-- |NLU|\n+---+   +----------------+   +---+   +---+   +-+-+\n                                               |\n                                               |\n+-------+   +---+   +----------------------+   |\n|Speaker| --|TTS| --|Knowledge/Skill/Action| --+\n+-------+   +---+   +----------------------+   Audio Processing includes Acoustic Echo Cancellation (AEC), Beamforming, Noise Suppression (NS), etc.  Keyword Spotting (KWS) detects a keyword (such as OK Google, Hey Siri) to start a conversation.  Speech To Text (STT)  Natural Language Understanding (NLU) converts raw text into structured data.  Knowledge/Skill/Action - Knowledge base and plugins (Alexa Skill, Google Action) to provide an answer.  Text To Speech", 
            "title": "To make a smart speaker"
        }, 
        {
            "location": "/make_a_smart_speaker/#kws-stt-nlu-skill-tts", 
            "text": "", 
            "title": "KWS + STT + NLU + Skill + TTS"
        }, 
        {
            "location": "/make_a_smart_speaker/#active-open-source-projects", 
            "text": "Mycroft  -  a hackable open source voice assistant  dingdang robot  - a Chinese voice interaction robot based on  Jasper  and built with raspberry pi", 
            "title": "Active open source projects"
        }, 
        {
            "location": "/make_a_smart_speaker/#sdk", 
            "text": "Amazon Alexa Voice Service - is the most widely used voice assistant    C++ SDK   Java Client   Python Client    Google Assistant SDK    It has the smartest brain, its extension called Google Action can be created on a few steps with digitalflow.ai and its Device Action is very suit for home smart devices.   Baidu DuerOS", 
            "title": "SDK"
        }, 
        {
            "location": "/make_a_smart_speaker/#kws", 
            "text": "Mycroft Precise  - A lightweight, simple-to-use, RNN wake word listener  Snowboy  - DNN based hotword and wake word detection toolkit  Honk  - PyTorch reimplementation of Google's TensorFlow CNNs for keyword spotting  ML-KWS-For-MCU  - Maybe the most promise for resource constrained devices such as ARM Cortex M7 microcontroller", 
            "title": "KWS"
        }, 
        {
            "location": "/make_a_smart_speaker/#stt", 
            "text": "Mozilla DeepSpeech  - A TensorFlow implementation of Baidu's DeepSpeech architecture  Kaldi  PocketSphinx  - a lightweight speech recognition engine using HMM + GMM", 
            "title": "STT"
        }, 
        {
            "location": "/make_a_smart_speaker/#nlu", 
            "text": "Rasa NLU    Rasa NLU for Chinese    Snips NLU  - a Python library that allows to parse sentences written in natural language and extracts structured information.", 
            "title": "NLU"
        }, 
        {
            "location": "/make_a_smart_speaker/#tts", 
            "text": "Mimic  - Mycroft's TTS engine, based on CMU's Flite (Festival Lite)  manytts  - an open-source, multilingual text-to-speech synthesis system written in pure java  espeak-ng  - an open source speech synthesizer that supports 99 languages and accents.  ekho  - Chinese text-to-speech engine  WaveNet, Tacotron 2", 
            "title": "TTS"
        }, 
        {
            "location": "/make_a_smart_speaker/#audio-processing", 
            "text": "Acoustic Echo Cancellation    SpeexDSP , its python binding  speexdsp-python    EC  - Echo Cancelation Daemon based on SpeexDSP AEC for Raspberry Pi or other devices running Linux.    Direction Of Arrival (DOA) - Most used DOA algorithms is GCC-PHAT    tdoa    odas  - ODAS stands for Open embeddeD Audition System. This is a library dedicated to perform sound source localization, tracking, separation and post-filtering. ODAS is coded entirely in C, for more portability, and is optimized to run easily on low-cost embedded hardware. ODAS is free and open source.    Beamforming    BeamformIt  - filter sum beamforming   CGMM Beamforming -  a reference implementation  MVDR Beamforming   GSC Beamforming    Voice Activity Detection    WebRTC VAD,  py-webrtcvad    DNN VAD    Noise Suppresion    NS of WebRTC audio processing,  python-webrtc-audio-processing", 
            "title": "Audio Processing"
        }, 
        {
            "location": "/make_a_smart_speaker/#audio-io", 
            "text": "PortAudio, pyaudio  libsoundio  ALSA  PulseAudio  Pipewire", 
            "title": "Audio I/O"
        }
    ]
}